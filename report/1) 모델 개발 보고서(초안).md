# 모델 개발 보고서
## 1. 프로젝트 개요 및 문제 접근법
### 1) 모델 설계 전략 및 접근법

- **문제 정의**
  - 운수종사자의 인지검사(A/B형) 결과와 과거 검사 이력을 활용하여 향후 **교통사고 위험도(사고 발생 확률)** 를 예측하는 이진 분류 모델 개발.
  - 대회 리더보드 평가는 AUC, Brier score, Expected Calibration Error(ECE)를 조합한 점수로 이루어지며, 단순 분류 성능뿐 아니라 **확률의 신뢰도(calibration)** 가 중요함.[1-2]

- **전체 아키텍처 개요**
  - **전처리·피처엔지니어링 모듈**
    - `1_Preprocess_v18_delta_logratio.py`
    - A/B형 검사 로그를 아래와 같은 **도메인 피처**로 변환  
      - 검사별 **기본 요약 피처(Base)**: 반응시간 mean/std, 조건별 평균, 조건별 정답률 등  
      - **고급 인지 지표**: Speed–Accuracy tradeoff, 반응시간 CV, Stroop/Flanker·주의 전환의 log-ratio
      - **PK 히스토리**: 누적 검사 횟수, A/B 유형별 검사 횟수, 검사 간 시간 간격(`pk_hist_*`)  
      - **Delta(B-only)**: 동일 운수종사자 직전 B 검사 대비 반응시간·정확도 변화량(`delta_*`)  
      - **정규화 피처**: 연령·검사 시점 z-score(`Age_num_z`, `YearMonthIndex_z`)
    - 최종적으로 통합 피처 테이블(`all_train_data.feather`)과 PK(운수종사자) 수준 이력·변화(Delta)를 계산하고, 연령/시점 정규화 수행하여 정규화 통계(`normalization_stats.pkl`) 저장

  - **모델 학습 모듈**
    - `2_Train_Models_v18_delta_logratio.py`
    - CatBoost 기반 **A/B 이원(dual) 모델 구조**
    - K-Fold `StratifiedKFold(n_splits=5)`으로 교차검증용 Fold 분할[1-1]
    - Fold별 Train 데이터에서만 **PK 통계(`PK Stats`)** 생성  
      - PK별 과거 반응시간·정확도·위험 점수의 평균/표준편차/최댓값 등
    - CatBoost 기반 **A/B 이원(dual) 모델 구조**로 학습  
      - 모델 A: A형 전용 – `Base + History + Normalization + log_ratio`  
      - 모델 B: B형 전용 – `Base + PK Stats + History + Normalization + Delta(B-only) + log_ratio`
    - 검증 세트 예측 확률에 대해 **Isotonic Regression**으로 확률 보정
      → Fold별 CatBoost 모델과 보정기를 저장하고, 추론 시 Fold 평균 앙상블로 최종 위험도 산출
- **모델 구조 선택 및 이유**
  - **CatBoostClassifier**
    - 범주형 변수(`Age`, `PrimaryKey`)를 직접 처리 가능
    - 결측치·비선형 관계에 강하고, 학습·튜닝이 안정적
    - 트리 기반 모델로 향후 SHAP 등을 통한 **설명 가능성** 확보 용이
  - **A/B 분리 모델**
    - A형과 B형의 검사 구성이 상이하고, 측정하는 인지 기능이 다르므로[2-0][2-2]
      두 검사를 하나의 모델로 묶기보다 **검사 유형별 전용 모델**을 설계.
    - **모델 A (A형 전용)**  
      - 구조: **Base + History + Normalization + log_ratio**  
        - *Base*: A형 각 검사에서 얻은 반응시간·정답률 등 기본 요약 피처  
        - *History*: `pk_hist_total_count`, `pk_hist_A_count/B_count`, 검사 간 간격 등 PK 이력 피처  
        - *Normalization*: `Age_num_z`, `YearMonthIndex_z`와 같이 연령·시점을 정규화한 피처  
        - *log_ratio*: Stroop/주의 전환 등 조건 간 반응시간·정확도의 로그 비율 지표[2-1]
      - A형은 검사 구성이 상대적으로 단순하고, PK Stats·Delta 없이도 충분한 신호를 제공한다고 판단해  
        구조를 간결하게 유지.
    - **모델 B (B형 전용)**  
      - 구조: **Base + PK Stats + History + Normalization + Delta(B-only) + log_ratio**  
        - *Base*: B형 각 검사의 반응시간·정확도 요약 피처[2-2]
        - *PK Stats*: 동일 PK의 과거 검사 결과를 Fold 내에서 평균·표준편차·최댓값 등으로 집계한 통계 피처  
        - *History*: 누적 검사 횟수·검사 간 간격 등 시간 이력 피처  
        - *Normalization*: 연령/시점 z-score 피처  
        - *Delta(B-only)*: 직전 B 검사 대비 변화량(예: 반응시간 증가, 정확도 감소 등)  
        - *log_ratio*: Flanker/Stroop 계열의 조건 간 비율 지표[2-2]
      - B형은 검사가 복잡하고 반복 검사 간 변화가 중요하다고 판단해  
        PK Stats와 Delta를 포함한 **풍부한 시간·개인차 정보**를 활용.

- **데이터 구조 및 검증 전략**
  - `PrimaryKey` 기준으로 반복 검사가 존재하는 **longitudinal 패널 데이터** 구조.
  - `StratifiedKFold(n_splits=5)`으로 Label 비율을 유지하며 교차검증 수행.[1-1]
  - Fold별로 학습된 CatBoost + Isotonic 모델을 저장하고, 추론 시 **Fold 평균 앙상블**로 안정적 예측값 산출.

- **데이터 누출 방지 전략**
  - PK 통계(PK Stats)는 각 Fold의 Train 데이터에서만 집계 후 같은 Fold의 Train/Validation에만 사용해 데이터 누출을 차단.[1-4]
  - B형 Delta 피처는 동일 PK의 직전 B 검사와의 차이만 사용하며, A형에서는 명시적으로 제거.

---

### 2) 기술적 차별성

1. **인지심리 도메인에 기반한 피처 설계**
   - `A1~A9`, `B1~B10` 검사는 Stroop, Flanker, 주의 전환, 시야각, 다중검사 등 인지심리학에서 운전 행동과 연관성이 검증된 검사를 포함.[2-0][2-2][2-3]
   - 단순 평균값이 아니라
     - 조건별 반응시간 평균·표준편차
     - 조건별 정답률
     - **Speed–Accuracy Tradeoff** (`rt_mean / acc`)
     - **반응시간 CV** (`rt_std / rt_mean`)
     - **조건 간 log_ratio** (`log(조건1 / 조건2)`)  
     등 인지 기능을 직접 반영하는 지표를 설계.[2-1]

2. **PK(개인) 수준 이력·변화량 활용**
   - `PrimaryKey` 기준으로 검사를 시간순 정렬하여
     - 누적 검사 횟수, A/B 유형별 누적 검사 횟수
     - 직전 검사 시점 및 검사 간 간격을 계산하고, 이를 **관리 사각지대에 있는 고위험군 탐지**에 활용.
   - B형에서는 직전 B 검사와의 차이(Delta)를 계산해
     - 인지 기능의 **개선/악화 추세**를 모델이 학습하도록 설계.
     - 이러한 개인별 이력·변화량 반영은 인지 기능과 사고 위험 간의 관계를 동적으로 파악해야 한다는 기존 연구 방향과도 일치.[2-3][2-4]

3. **확률 보정 중심의 위험도 모델**
   - 단순 분류 정확도보다 **실제 사고 확률에 근접한 위험도**를 제공하기 위해
     - CatBoost 출력 확률을 Isotonic Regression으로 보정.[1-1][1-2]
     - AUC, Brier, ECE를 동시에 고려한 Combined Score를 내부 지표로 사용.[1-2][1-4]
   - 의료·안전 분야에서 활용되는 모범 사례를 교통사고 위험 예측에 접목해 정책·교육 의사결정에 적합한 예측 확률을 제공.[1-3][1-5]

4. **일반화 구조 및 운영 편의성**
   - 연령·검사 시점은 z-score로 정규화하여 특정 시기·집단에 과도하게 특화되지 않도록 일반화 성능을 확보.[1-4]
   - 전처리·학습·추론이 모두 스크립트화되어 있어 데이터만 교체하면 재학습·재배포가 가능한 구조.[1-0]

---

### 3) 개발 환경 및 도구 구성

| 구분 | 도구/라이브러리               | 버전(예) | 제조사(출처)                  | 용도                                   |
|------|-------------------------------|---------|--------------------------------|----------------------------------------|
| 1    | Python, Jupyter Notebook      | 3.10.19    | Python Software Foundation     | 전처리, 모델링, 실험 환경             |
| 2    | pandas, numpy, pyarrow | 2.2.2, 1.26.4, 22.0.0| Open Source / Apache                    | 데이터 로드·가공, 피처 엔지니어링     |
| 3    | CatBoost                      | 1.2.8     | Yandex                         | Gradient Boosting 기반 이진 분류 모델 |
| 4    | scikit-learn                  | 1.5.2     | scikit-learn community         | K-Fold, 평가 지표, Isotonic Regression|
| 5    | joblib, tqdm                  | 1.5.2, 4.66.5    | Open Source                    | 모델·통계 저장, 학습 진행률 표시      |

---

## 2. 상세 개발 방법론

### 1) 모델 구조 상세

#### (1) 입력 → 전처리 및 피처 생성 → 모델 학습 및 확률 보정 → 추론 단계

- **입력(Data Ingestion)**
  - 메타 데이터: `train.csv`  
    - `PrimaryKey`, `Test`(A/B), `Label`, `Age`, `TestDate` 등
  - 검사 로그: `train/A.csv`, `train/B.csv`  
    - 각 인지검사별 반응시간/정답 여부 시퀀스[2-0][2-2]

- **전처리 및 피처 생성**
  - `1_Preprocess_v18_delta_logratio.py`
     - `Age`를 숫자형 `Age_num`으로 변환  
     - `TestDate`를 `Year`, `Month`, `YearMonthIndex`로 분해
     - `preprocess_A()`, `preprocess_B()`  
       → 검사별 반응시간 평균·표준편차, 조건별 정답률 등 1차 도메인 피처 생성  
     - `add_features_A()`, `add_features_B()`  
       → Speed–Accuracy, CV, log_ratio, z-score 등 2차 피처 생성[2-1]
     - PK 히스토리 및 Delta(B-only) 생성  
       → `pk_hist_*`, `delta_*` 컬럼
     - 결과를 `all_train_data.feather`로 저장, 정규화 통계를 `normalization_stats.pkl`에 저장.

- **모델 학습 및 확률 보정**
  - `2_Train_Models_v18_delta_logratio.py`
     - `StratifiedKFold(n_splits=5)`으로 Train/Validation 분할
     - 각 Fold의 Train 데이터에서 PK Stats 생성 (`pk_stats_fold`)
     - A/B 데이터 분리 후
       - `train_model_A()` : PK Stats/Delta 없이 CatBoost 학습 + Isotonic 보정  
       - `train_model_B()` : PK Stats + Delta 포함 CatBoost 학습 + Isotonic 보정
     - Fold별 모델(`catboost_A/B_fold*.pkl`)과 보정기(`calibrator_A/B_fold*.pkl`) 저장
     - Fold별 PK Stats를 평균 내어 `pk_stats_final.csv`로 저장

- **추론(서비스) 단계**
  - 신규 데이터에 대해 위와 동일한 전처리 수행  
  - `normalization_stats.pkl`, `pk_stats_final.csv`를 로드하여 동일한 스케일·통계를 적용
  - 검사 유형(A/B)에 따라 해당 Fold 모델 + 보정기를 모두 적용한 후
    - Fold별 예측 확률의 평균을 **최종 위험도**로 사용

#### (2) 핵심 모듈 및 알고리즘 역할

- `preprocess_A/B()`  
  - 시퀀스 형태의 검사 로그를 **인지 기능 요약 지표**로 변환하는 핵심 모듈.
- `add_features_A/B()`  
  - log_ratio, speed–accuracy, CV, z-score 등 **도메인 해석 가능한 2차 피처** 생성.
- `add_delta_features_pk()`  
  - B형 수치 피처에 대해 PK별 직전 값과의 차이를 계산하여 **인지 기능의 변화율**을 표현.
- `train_model_A/B()`  
  - CatBoostClassifier를 이용해 이진 분류 모델을 학습하고,  
    Isotonic Regression으로 확률을 보정하여 **신뢰도 높은 위험도 점수**를 산출.
- `expected_calibration_error()`, `combined_score()`  
  - ECE, Combined Score를 계산하여 **모델의 확률 보정 품질**을 정량 평가.

---

### 2) 외부 지식 활용 및 전략

1. **인지심리학 및 운전 행동 연구 기반 피처 설계**
   - Stroop, Flanker, 주의 전환(Attentional Cueing), 시야각, Hazard Perception 등  
     고위험도 도메인(의료·운전)에서 반복적으로 검증된 검사를 참고.[2-0][2-2][2-3]
   - 문헌에서 공통적으로 사용하는 지표
     - 조건 간 반응시간 차이·비율
     - 정확도/오류율
     - Speed–Accuracy Tradeoff
   - 이를 반영해
     - Stroop/Flanker 간섭 효과를 `log(조건1/조건2)` 형태로 정의하고,[2-1][2-2]
     - 조건별 정확도·반응시간 비율을 주요 피처로 채택.[2-3][2-4]

2. **고위험도 예측 모델의 평가 지표**
   - 의료·위험 관리 분야에서는 AUC뿐 아니라 **Brier score, ECE** 등 확률 보정 지표를 함께 사용.
   - 관련 논문을 참고하여
     - CatBoost 출력 확률을 Isotonic Regression으로 보정하고,[1-2]
     - Reliability curve, ECE 등을 내부 점검 지표로 활용.[1-4]
   - 이를 통해 "위험도 = 실제 사고 확률에 근접한 숫자"를 목표로 하는 모델을 설계.

3. **인적요인·교통 안전 도메인 지식**
   - 운수종사자의 연령, 근무 연차, 반복 검사 경험은 인지 기능과 사고 위험에 영향을 미칠 수 있다는 선행 연구를 참고하여
     - `Age_num`, `Age_num_z`, `pk_hist_*`, `pk_test_*_count` 등 피처로 구현.[2-3][2-4] 
   - Hazard Perception 교육이 사고 위험을 감소시킨다는 연구를 참고해 향후 **교육·훈련 효과 시뮬레이션**을 위한 구조(Delta, PK Stats)를 설계.

---

### 3) 모델 튜닝 및 최적화 전략

#### (1) 하이퍼파라미터 설정 및 버전별 개선 과정

모델 개발 과정에서 여러 버전을 실험하며 **모델 성능과 ECE를 지속적으로 개선**하였다.[1-2][1-4]

- **v0 (베이스라인)**
  - 단순 수치 요약 + CatBoost 단일 모델
  - PK 이력·Delta·log_ratio 미사용
  - 리더보드 기준, 베이스라인 수준의 점수 확인

- **v1~v17: 도메인 피처 및 히스토리 반영**
  - A/B 검사의 반응시간·정답률을 검사별로 요약하는 1차 피처 추가
  - `pk_hist_total_count`, `pk_hist_A/B_count`, `pk_hist_gap_from_prev` 등 이력 피처 도입
  - **효과**
    - AUC 개선 및 리더보드 점수 상승
    - PK 이력 피처 추가 후, 고위험 PK에 대한 분별력이 향상됨을 내부 분석에서 확인

- **v18: PK Stats 도입 + K-Fold 구조 안정화**
  - Train Fold에서만 집계한 PK 통계(PK Stats)를 B형 모델에 주입[1-4]
  - 모델 구조를 A/B 이원 구조로 분리
  - **효과**
    - B형에서의 AUC 개선 및 리더보드 점수 추가 향상
    - PK별 평균/편차 정보를 활용해 개인차를 보다 안정적으로 반영

- **v18 + Delta + log_ratio (최종)**
  - 본 보고서에서 사용하는 버전
  - 변경 사항
    - 주요 인지 효과를 *cost*가 아닌 **log_ratio** 기반으로 재정의  
      (예: Stroop/Flanker, 주의 전환의 조건 간 비율)
    - B형 수치 피처에 대해 PK 기준 직전 값과의 차이(Delta) 도입
    - CatBoost 하이퍼파라미터를 A/B에 맞게 분리 튜닝[1-0]
  - **효과**
    - 내부 Combined Score 기준으로 v18 대비 추가 개선[1-4]
    - ECE 감소(확률 보정 품질 개선)와 함께 리더보드 Public 점수도 상승

#### (2) Optuna 기반 하이퍼파라미터 탐색(HPO)

최종 CatBoost 하이퍼파라미터는 수작업 튜닝에 더해, `3_Tune.py`에서 **Optuna 기반 자동 하이퍼파라미터 탐색(HPO)** 을 수행해 결정하였다.

- **튜닝 전략**
  - 전체 5-Fold 중 계산 비용을 고려해 `FOLDS_FOR_TUNING = [0, 1, 2]` 세 Fold만 사용.
  - 각 Trial에서
    1. 선택된 파라미터로 CatBoost 학습
    2. 각 Fold의 Validation 세트에 대해 예측 확률 산출
    3. Validation 확률을 Isotonic Regression으로 보정
    4. 세 Fold의 예측을 합쳐 **Combined Score** 계산 후, 이를 Optuna 목적 함수로 최소화
  - Combined Score 정의:
    \[
    \text{Combined Score} = 0.5(1-\text{AUC}) + 0.25\times\text{Brier} + 0.25\times\text{ECE}
    \]
    → 단일 지표로 AUC·Brier·ECE를 동시에 관리하도록 설계.

- **A형 모델 튜닝 (`objective_A`)**
  - 설계 정책에 따라 **PK Stats·Delta 피처는 사용하지 않도록 고정**.
  - 검색 공간(예시):
    - `depth ∈ [4, 8]`
    - `learning_rate ∈ [0.02, 0.2]` (log scale)
    - `l2_leaf_reg ∈ [1e-2, 10.0]` (log scale)
  - Fold별로 A형 데이터만 추출한 뒤, `delta_` 접두어 컬럼을 제거하고 `_build_cb_matrices()`로 CatBoost 입력을 구성하여 Trial별 Combined Score를 계산.

- **B형 모델 튜닝 (`objective_B`)**
  - **PK Stats + Delta + log_ratio**를 모두 사용하는 구조를 유지한 상태에서 탐색.
  - 검색 공간(예시):
    - `depth ∈ [3, 7]`, `learning_rate ∈ [0.01, 0.1]`
    - `l2_leaf_reg`, `random_strength`, `bagging_temperature ∈ [1e-2, 10.0]` (모두 log scale)
    - `border_count ∈ [64, 255]`
  - Fold별 Train 데이터에서 `build_pk_stats_fold()`로 PK Stats를 **해당 Fold 내부에서만 집계**하여 데이터 누출을 방지한 뒤, B형 데이터에 merge하여 Combined Score를 계산.

- **결과 활용**
  - Optuna Study 종료 후 `study.best_params`를 `v18_best_params_{group}_optuna.pkl`로 저장하고,
  - 최종 학습 스크립트(`2_Train_Models_v18_delta_logratio.py`)의 `BEST_A_PARAMS`, `BEST_B_PARAMS` 설정에 반영(필요 시 소폭 수동 보정)하여 리더보드·실무 환경에서 모두 안정적인 파라미터 조합을 사용

#### (3) 최종 하이퍼파라미터

- **모델 A**
  - `depth = 6`, `learning_rate = 0.05`, `l2_leaf_reg = 3`
  - Delta/PK Stats가 없는 단순 구조를 고려해, 깊이는 다소 크게 설정하여 비선형 관계를 충분히 학습
- **모델 B**
  - `depth = 3`, `learning_rate = 0.03`, `l2_leaf_reg = 5`
  - `random_strength = 3.0`, `bagging_temperature = 1.0`, `border_count = 128`
  - Delta와 PK Stats로 피처 수가 많고 상관성이 높으므로 얕은 트리 + 강한 정규화 + 샘플링 노이즈로 과적합을 억제

#### (4) Combined Score 기반 모델 선택

- 내부 평가 지표:
  - AUC, Brier, ECE를 모두 계산하여[1-2][1-3]
  - `Combined Score = 0.5*(1-AUC) + 0.25*Brier + 0.25*ECE`[1-5]
- 다양한 피처 조합/하이퍼파라미터를 실험한 후
  - Combined Score와 리더보드 Public 점수를 함께 비교하여 **예측력과 확률 신뢰도를 동시에 만족하는 현재 버전**을 최종 모델로 선정.

---

## 3. 모델 구현 상세 설명

### 1) 주요 프로세스 및 실행 흐름

1. **전처리 단계 – `1_Preprocess_v18_delta_logratio.py`**
   - 데이터 로드
     - `train.csv`, `train/A.csv`, `train/B.csv` 읽기
   - 인적·시점 파생
     - `convert_age()`로 `Age` → `Age_num`
     - `split_testdate()`로 `TestDate` → `Year`, `Month`
     - `YearMonthIndex = Year*12 + Month` 계산
   - 인지검사별 1차 피처
     - `preprocess_A(df)`, `preprocess_B(df)`  
       - 반응시간 평균·표준편차(`seq_mean`, `seq_std`)  
       - 조건별 평균·정확도(`masked_operation`, `seq_rate_*`)  
       - 정답 개수, 설문 문항 점수 등
   - 2차 도메인 피처
     - `add_features_A(df)`, `add_features_B(df)`  
       - Speed–Accuracy Tradeoff, CV, log_ratio, z-score
   - PK 히스토리 및 Delta(B-only)
     - 그룹 정렬 후 `pk_hist_*` 생성
     - `add_delta_features_pk(df, test_col_name)`로 B형 수치 피처의 직전 값과 차이 계산
   - 산출물 저장
     - `all_train_data.feather`, `normalization_stats.pkl` 저장

2. **학습 단계 – `2_Train_Models_v18_delta_logratio.py`**
   - 데이터 로드 및 Fold 분할
     - `all_train_data.feather` 로드
     - `StratifiedKFold(5)`으로 인덱스 리스트 생성
   - 공통 유틸
     - `expected_calibration_error()`, `combined_score()`  
       → ECE 및 Combined Score 계산
     - `_build_cb_matrices()`  
       → 수치/범주 피처 분리 및 CatBoost 입력 행렬 구성
   - Fold 루프
     - 각 Fold의 Train 데이터에서 PK Stats 집계 → `pk_stats_fold`
     - A/B 데이터 분할 → `train_model_A()`, `train_model_B()` 호출
     - Isotonic Regression으로 확률 보정 후  
       Fold별 모델 및 보정기 저장
   - 최종 PK Stats
     - Fold별 `pk_stats_fold`를 평균 내어 `pk_stats_final.csv` 저장

### 2) 주요 함수·파일 및 파라미터 설정

- **파일 구조**
  - `1_Preprocess_v18_delta_logratio.py` : 전처리 및 피처엔지니어링
  - `2_Train_Models_v18_delta_logratio.py` : 학습·평가·모델 저장
- **핵심 함수**
  - `preprocess_A/B`, `add_features_A/B`, `add_delta_features_pk`
  - `expected_calibration_error`, `combined_score`
  - `train_model_A`, `train_model_B`
- **중요 파라미터**
  - K-Fold 수: 5  
  - CatBoost iterations: 3000, early_stopping_rounds: 100  
  - 범주형 피처: `['Age', 'PrimaryKey']`  

---

## 4. 결론 및 향후 발전 방향

### 1) 실무 적용 가능성 평가

본 모델은 현재 대회 데이터 구조(메타정보 + A/B형 인지검사 로그)를 그대로 가정하여 설계했기 때문에, 실제 인지검사 시스템과 비교적 적은 수정으로 연계할 수 있다. 또한 해외에서 이미 유사한 개념(인지검사·Hazard Perception Test·주행 리스크 점수 등)이 실무에 적용되고 있다는 점에서 정책 도입 측면의 타당성도 확보할 수 있다.

##### (1) 기존 인지검사 시스템과의 연계

- 운수종사자가 A/B형 인지검사를 완료하면, 해당 로그를 그대로 전처리 파이프라인(`1_Preprocess_v18_delta_logratio.py`)에 투입해 **도메인 기반 요약 피처 + PK 이력 + Delta(변화량)**를 자동 생성할 수 있다.
- 학습 시 저장해 둔  
  - `normalization_stats.pkl` (연령/검사시점 정규화 통계)  
  - `pk_stats_final.csv` (PK별 과거 검사 통계)  
  를 함께 로드하면, **추가 학습 없이도 동일 스케일에서 위험도 산출**이 가능하다.
- 즉, 기존 적성·자격검사 시스템에
  1) 검사 로그 적재  
  2) 전처리 스크립트 실행  
  3) CatBoost + Isotonic 모델 호출  
  의 세 단계를 추가하는 것만으로, "검사 완료 → 수 분 내 위험도 산출"이 가능한 구조다.

> 해외에서도 인지검사·Hazard Perception Test 성적을 운전면허/안전관리와 직접 연결하는 사례가 보고된다.  
> 예를 들어 영국에서는 면허 이론시험에 **Hazard Perception Test(HPT)**를 도입한 이후, HPT 점수가 낮은 집단이 실제 충돌 위험이 더 높고, 훈련·테스트 도입으로 충돌사고가 약 11% 감소했다는 분석이 있다.[3-0]
> 호주·뉴질랜드에서도 화물·버스 운전자를 대상으로 별도의 HPT를 개발해 **면허·자격 제도에 통합하는 방안**을 논의 중이다.[3-1]

본 프로젝트의 위험도 모델은 이러한 HPT·인지검사 기반 정책과 구조적으로 유사하며, **점수 산출 방식만 기계학습으로 고도화한 형태**라고 볼 수 있다.

---

##### (2) 위험도 등급화 및 관리 정책 연계

- 보정된 확률값은 그대로 **향후 일정 기간 내 사고 발생 확률**에 대한 추정치로 간주할 수 있다.
- 실제 적용 시에는 기관이 보유한 사고 이력 데이터와 결합하여, 예를 들어 다음과 같이 **위험도 구간별 관리 기준**을 정의할 수 있다.
  - 상위 5%: **고위험군(Red)** – 추가 정밀검사, 심화 교육 의무화, 근무 패턴(야간·장거리) 선제 조정
  - 상위 5~20%: **주의군(Amber)** – 집중 모니터링, 단기 교육·코칭 프로그램 권고
  - 나머지: **일반군(Green)** – 정기검사 주기 유지
- 해외 연구에서는 기억·주의·시공간 능력 등을 측정하는 **인지 기능 검사 배터리 성적이 높은 집단이 사고 위험이 낮다**는 결과가 반복적으로 보고되고 있다.[3-2]
  이와 같은 근거를 활용하면, 우리 모델에서 산출된 위험도 구간을 **정책적으로 설득력 있는 기준**으로 제시할 수 있다.

또한 일본에서는 75세 이상 고령 운전자의 면허 갱신 시 인지 기능 검사를 도입했고, 이 정책과 교통사고 위험 간의 관계를 평가하는 연구들이 이미 축적되고 있다.[3-3]
비록 정책 효과에 대한 평가는 연구마다 차이가 있지만, **인지검사 결과를 토대로 고위험군을 별도 관리하는 방향** 자체는 국제적으로 널리 논의되고 있다는 점을 시사한다.[3-4]

---

##### (3) 운수회사·지자체용 대시보드와 운영 시나리오

- 본 모델이 산출하는 정보를 집계하면 다음과 같은 **현장용 대시보드** 구성이 가능하다.
  - 노선·사업장별 고위험 운수종사자 비율
  - 연령대·근무형태(야간/장거리 등)별 평균 위험도·사고율
  - 교육 수료 전·후 인지지표 및 위험도 변화 추이
- 이는 해외에서 주행 데이터 기반 운전 위험 점수(Driving Risk Score)를 보험료 산정·고위험 운전자 코칭에 활용하는 방식과 유사한 구조다.[3-5]
  이미 사용중인 Usage-Based Insurance(UBI)·텔레매틱스 프로그램에서는 급가속·급제동·코너링 등 지표를 종합해 리스크 점수를 만들고, 이를 **요율·보상·피드백 시스템에 실시간 반영**하고 있다. 본 프로젝트는 동일한 아이디어를 인지검사 데이터에 적용한 사례라고 정리할 수 있다.

실제 운영 관점에서는 다음과 같은 시나리오를 제안할 수 있다.

1. **정기검사 연계**
   - 인지검사 결과를 모델에 입력해 위험도를 산출하고,  
     일정 기준 이상인 운수종사자에 대해서만 추가 심리검사·실기평가를 진행함으로써 **검사 자원을 고위험군에 집중 배분**.
2. **교육·개입 효과 측정**
   - 교육 전/후 인지검사와 위험도를 비교해,  
     특정 교육 프로그램이 Stroop/Flanker 성능과 실제 위험도 점수에 어떤 영향을 미치는지 평가.
3. **지속적 모니터링 및 재학습**
   - 새로 축적되는 검사·사고 데이터를 반기 또는 연 1회 주기로 반영해 재학습을 수행하고,  
     재학습 전후 AUC/Brier/ECE 및 입력 분포를 비교함으로써 **데이터 드리프트와 모델 열화 여부를 모니터링**.

---

##### (4) 현장 활용 시 기대 효과

- 정기 인지검사에서 도출된 **정량적 위험도 점수**를 통해, 사고가 발생하기 전에 **고위험 운수종사자에 대한 선제적 개입**(교육·휴식 권고·노선 조정 등)이 가능해진다.
- 이는 이미 여러 국가에서 HPT 성적·인지검사 결과를 기반으로 면허 정책을 조정하거나 고령 운전자 관리를 강화하는 움직임과 방향성이 같다.[3-6]
- 장기적으로는
  - 인지검사 설계(어떤 과제를 넣을지, 어떤 점수 조합이 사고와 가장 강하게 연관되는지),
  - 교육 프로그램(어떤 인지 영역을 중점적으로 훈련해야 하는지)
  를 **실제 위험도·사고 데이터와 연결해 순환적으로 개선**할 수 있는 기반을 제공한다.

요약하면, 본 모델은 **기존 인지검사 시스템에 자연스럽게 접목할 수 있는 구조**를 가지면서도, 해외의 인지검사·HPT·주행 리스크 점수 사례에서 이미 검증된 아이디어를 바탕으로 하고 있기 때문에, 정책·실무 측면에서 충분한 적용 가능성을 가진다고 판단된다.

---

### 2) 향후 발전 방향

1. **설명 가능성(Explainability) 강화**
   - SHAP 값을 이용해 각 인지 영역이 위험도에 미치는 기여도를 산출하고, 운수종사자별 **개인 맞춤형 피드백 리포트** 생성 기능을 추가.

2. **추가 데이터 결합 및 모형 고도화**
   - 사고 이력, 운행 거리·시간, 근무 형태와의 결합을 통해 인지검사 기반 위험도와 실제 사고 발생 간의 관계를 정교하게 모델링.
   - 필요 시 시계열/생존모델(예: Cox, DeepSurv 등)로 확장하여 "다음 1년 내 사고 발생 확률"과 같은 시간 개념을 반영.

3. **교육·개입 시뮬레이션**
   - 특정 인지지표(예: Stroop 간섭, Flanker 정확도)가 개선되었을 때 예측 위험도가 얼마나 감소하는지 시뮬레이션함으로써 교육 프로그램 설계 및 정책 효과 평가에 직접 활용.

---

## 5. 참고자료 및 인용 모델 출처

### (1) 모델링 및 확률 보정 관련
- Yandex, **CatBoost Documentation** – CatBoost 알고리즘 및 파라미터 설명. [1-0]  
- scikit-learn documentation – StratifiedKFold, IsotonicRegression, ROC AUC, Brier score 등 구현 참고. [1-1]  
- Niculescu-Mizil, N., & Caruana, R. (2005). *Predicting Good Probabilities with Supervised Learning*. ICML. [1-2]  
- Assel, M., et al. (2017). *The Brier score does not evaluate the clinical utility of diagnostic tests or prediction models*. Journal of Urology. [1-3]  
- Šuster, S., et al. (2023). *Analysis of predictive performance and reliability of machine learning models*. Computer Methods and Programs in Biomedicine. [1-4]  
- Kattan, M. W., et al. (2018). *The index of prediction accuracy: an intuitive measure useful for decision-analytic model evaluation*. Diagnostic and Prognostic Research. [1-5]  

### (2) 인지심리학 / 운전 행동 연구

- Stroop, J. R. (1935). *Studies of Interference in Serial Verbal Reactions*. Journal of Experimental Psychology. – 스트룹 효과 원전. [2-0]  
- Scarpina, F., & Tagini, S. (2017). *The Stroop Color and Word Test*. Frontiers in Psychology. – Stroop 검사를 이용한 실행 기능 평가 리뷰. [2-1]  
- Eriksen, B. A., & Eriksen, C. W. (1974). *Effects of noise letters upon the identification of a target letter in a nonsearch task*. Perception & Psychophysics. – Flanker task 제안 논문. [2-2]  
- Omran, Y. H., et al. (2023). *Driving Hazard Perception Tests: A Systematic Review*. Safety. – 운전 상황 Hazard Perception 테스트의 신뢰도·타당도 검토. [2-3]  
- Prabhakharan, P., et al. (2024). *The efficacy of hazard perception training and education*. Accident Analysis & Prevention. – Hazard perception 훈련이 실제 사고 위험 감소에 미치는 효과 분석. [2-4]  

### (3) 실무 적용 사례
- Driver and Vehicle Standards Agency (DVSA). *Hazard perception test wins road safety awards* (GOV.UK, 2014). – 영국 운전면허 이론시험에 Hazard Perception Test(HPT)를 도입한 이후, 특정 유형의 교통사고가 약 11% 감소했다는 연구 결과와 함께 정책 효과가 소개됨.[3-0]
- Omran, Y. H. et al. (2023). *Driving Hazard Perception Tests: A Systematic Review*. Safety. – 다양한 HPT 도구의 신뢰도·타당도와 실제 사고 관여와의 연관성을 정리한 체계적 문헌고찰로, 위험지각 점수가 낮은 집단의 사고 위험이 높다는 근거를 제시.[3-1]
- Horswill, M. S. et al. (2008). *Hazard Perception Ability of Older Drivers*. The Journals of Gerontology: Series B. – 고령 운전자의 Hazard Perception 반응 시간이 유의하게 느리고, 시지각·주의 능력이 사고 위험과 밀접하게 연관됨을 보인 연구.[3-2]
- Ichikawa, M. et al. (2020). *Increased traffic injuries among older unprotected road users after the introduction of cognitive tests at license renewal in Japan*. Accident Analysis & Prevention. – 일본에서 75세 이상 운전자 면허 갱신 시 인지기능검사를 도입한 이후 교통사고 양상을 분석한 연구.[3-3]
- Lim, G. Y. et al. (2023). *Which Cognitive Tasks Predict Traffic Accidents in Middle-Aged and Older Adult Drivers?* Korean Journal of Industrial and Organizational Psychology. – 주의 범위(UFOV), 시공간 판단, 시공간 작업기억, 멀티태스킹 등 개별 인지 과제가 실제 교통사고 경험을 얼마나 잘 예측하는지 분석.[3-4]
- NAIC & 각 주 보험 감독당국. *Understanding Usage-Based Insurance (UBI)*, Consumer Insight 자료 및 관련 안내문. – 주행거리·시간·급가속·급제동·코너링 등 운전 행태 데이터를 수집해 보험료를 차등화하는 UBI/텔레매틱스 프로그램 개요를 제공.[3-5]
- Boylan, J. et al. (2024). *A systematic review of the use of in-vehicle telematics for monitoring driving behaviour and insurer risk*. Accident Analysis & Prevention. – 차량 내 텔레매틱스 데이터와 머신러닝을 활용해 보험·안전 분야에서 운전 위험 점수를 산출하는 최근 연구들을 정리.[3-5]
- Road & Track (2025). *A Real-World Driving Game Has Reportedly Reduced Car Crashes in Korea*. – 국내 Tmap Mobility의 주행 점수(Driving Score) 기반 게이미피케이션·보험 할인 프로그램이 2018~2020년 약 3만 건 이상의 사고 감소에 기여했다는 사례 소개.[3-6]

---
