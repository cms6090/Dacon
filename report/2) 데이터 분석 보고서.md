# 데이터 분석 보고서

## 1. 프로젝트 개요 및 문제 접근법

### 1) 데이터 전처리 및 접근 방법

- **데이터 구조**
  - 메타 데이터: `train.csv`  
    - 주요 컬럼: `PrimaryKey`(운수종사자 ID), `Test`(A/B형), `Test_id`, `Label`(사고 발생여부), `Age`, `TestDate` 등
  - 인지검사 로그:
    - `train/A.csv`: A형 검사(A1~A9) 시퀀스 데이터
    - `train/B.csv`: B형 검사(B1~B10) 시퀀스 데이터
  - 동일 운수종사자(`PrimaryKey`)에 대해 여러 시점의 검사가 존재하는 **반복 측정(longitudinal) 패널 구조**로,  
    시간에 따른 인지 기능 변화까지 고려할 수 있는 형태임.

- **전처리 및 피처 생성 접근**
  - 전처리 파이프라인: `1_Preprocess_v18_delta_logratio.py`
  - 주요 단계 개요
    1. **기본 파생**
       - `Age` → `Age_num` (예: “40a/40b” → 구간 대표값)  
       - `TestDate` → `Year`, `Month`, `YearMonthIndex = Year * 12 + Month`
    2. **1차 도메인 피처(검사별 요약)**
       - A형: `preprocess_A()`  
         - A1~A5 반응시간 mean/std, 조건별(acc, rt), A6·A7 정답 개수, A8·A9 설문 점수 등
       - B형: `preprocess_B()`  
         - B1~B5 반응시간·정확도 요약, B6~B8 정답률, B9~B10 다중과제 점수 등
    3. **2차 도메인 피처(log_ratio 등)**
       - `add_features_A()`, `add_features_B()`
       - Speed–Accuracy Tradeoff, 반응시간 CV, 조건 간 log-ratio(예: Stroop/Flanker 간섭 효과) 생성
    4. **PK 기반 히스토리 피처**
       - `pk_hist_total_count` (누적 검사 횟수)
       - `pk_hist_A_count`, `pk_hist_B_count` (유형별 누적 검사 횟수)
       - `pk_hist_gap_from_prev` (이전 검사 시점과의 간격)
    5. **정규화 점수**
       - `Age_num_z`, `YearMonthIndex_z`: 데이터 전체 기준 z-score
       - 통계량은 `normalization_stats.pkl`에 저장
    6. **Delta(B-only) 피처**
       - B형 관련 수치 피처(B1~B10 요약값)에 대해  
         동일 PK 기준 직전 검사 값과의 차이(`delta_B*_…`) 계산
       - A형에는 Delta를 적용하지 않고, B형에서만 사용
    7. **최종 저장**
       - 모든 메타·도메인 피처·히스토리·Delta를 통합한  
         `all_train_data.feather` 생성 (모델/EDA 공통 입력)

- **전처리 원칙**
  - **데이터 누락/에러 처리**
    - 시퀀스가 비어 있는 경우 NaN으로 치환하여 이후 계산에서 제외
    - 나누기 연산에는 `eps=1e-6`을 사용하여 0으로 나누는 오류 방지
  - **데이터 누출(leakage) 방지**
    - 전처리 단계에서는 PK Stats(평균 RiskScore 등)는 계산하지 않고,
      학습 코드(`2_Train_Models_v18_delta_logratio.py`)에서 **Fold별 Train 데이터로만** 집계
  - **일관된 스케일**
    - 연령·시점 기반 z-score를 통해 특정 시기·연령대에 과도하게 특화되지 않도록 설계

---

### 2) 탐색적 데이터 분석(EDA)

EDA는 최종 모델 설계 이전에 “데이터가 실제로 어떤 구조와 패턴을 가지는지”를 확인하고,  
필요한 피처·모델링 전략을 결정하기 위해 수행하였다. 보고서에서 정리한 주요 축은 다음과 같다.

1. **기본 분포 및 라벨 구조**
   - `Test`(A/B형)별 데이터 건수와 `Label` 비율 비교
   - `PrimaryKey` 기준 검사 횟수 분포 (`pk_hist_total_count`)  
     → “1회 검사만 받은 PK” vs “주기적으로 검사 받는 PK” 그룹 확인
   - `Age_num`, `Age_num_z` 분포 및 `TestDate`, `YearMonthIndex` 분포  
     → 연령/시점 별 데이터 편중 여부 확인

2. **인지검사 요약 피처 분포**
   - 주요 반응시간 피처 예시
     - A1/A2/A3/A4/B3/B4의 `*_rt_mean`, `*_rt_std`  
       → 전반적으로 오른쪽 꼬리가 긴(느린 반응이 일부 존재하는) 분포
   - 주요 정확도 피처 예시
     - `A4_acc_congruent`, `A4_acc_incongruent`, `B4_congruent_acc`, `B4_incongruent_acc` 등
     - 대다수는 높은 정확도를 보이지만, 일부 PK/시점에서 극단적으로 낮은 정확도가 관찰되는지 여부 확인

3. **Speed–Accuracy 및 log-ratio 피처 확인**
   - `*_speed_acc_tradeoff` 분포 → 반응시간이 빠른 대신 정확도가 낮은 유형 vs 반대 유형 구분 가능성 확인
   - `A4_stroop_rt_log_ratio`, `A4_stroop_acc_log_ratio`, `B4_flanker_acc_log_ratio` 등  
     Stroop/Flanker 계열 검사에서 **조건 간 차이(간섭 효과)** 가 잘 드러나는지 확인

4. **PK 히스토리/Delta 패턴**
   - `pk_hist_total_count`, `pk_hist_gap_from_prev`  
     → 반복 검사 간 간격이 촘촘한지/드문지에 따라 인지 변화 추세를 볼 수 있는지 확인
   - B형 Delta 피처(`delta_B*_…`)  
     → 직전 검사 대비 반응시간 증가·정확도 감소 등의 변화 방향과 크기가 과도하게 노이즈인지,  
       혹은 일정 패턴을 보이는지 검토

5. **상관 및 다중공선성 구조**
   - 주요 피처 그룹 간 상관계수 행렬(예: 반응시간 계열 vs 정확도 계열 vs log-ratio 계열)
   - 높은 상관을 보이는 피처들은 **도메인 해석이 더 명확한 피처를 중심으로** 사용하거나,  
     트리 기반 모델 특성을 고려해 유지하되 중요도를 통해 후처리하는 전략 선택

EDA 결과는 “어떤 피처가 실제로 Label과 의미 있는 관계를 가질 수 있는지”에 대한 가설을 강화하는 데 사용되었다.

---

### 3) 결과 및 인사이트 요약

EDA를 통해 얻은 핵심적인 정리 포인트는 다음과 같이 요약할 수 있다.

1. **데이터 구조 인사이트**
   - 동일 운수종사자에 대해 “여러 시점의 인지검사 + 사고 라벨”이 관측되는 구조이므로,  
     **개인 수준 이력(PK 히스토리)과 시간 변화(Delta)를 활용하는 것이 타당**하다.
   - A형과 B형의 과제 구성·난이도·측정 인지 기능이 다르기 때문에,  
     두 유형을 하나의 피처 공간으로 단순 병합하기보다는 **검사 유형별 모델(A/B 분리)** 접근이 자연스럽다.

2. **인지 피처 인사이트**
   - 단순 평균 반응시간/정확도뿐 아니라,  
     **조건 간 log-ratio, CV, Speed–Accuracy Tradeoff**와 같은 2차 피처가  
     개별 과제의 인지 특성(주의 전환, 억제 기능, 시야각, 멀티태스킹 등)을 더 직접적으로 표현한다.
   - 특히 Stroop/Flanker 계열에서는 log-ratio 기반 지표가  
     “간섭 효과가 얼마나 강한지”를 한 번에 보여주는 장점이 있어,  
     **핵심 인지 리스크 지표**로 채택하였다.

3. **운영 및 평가 관점 인사이트**
   - 라벨 구조상 **정확도(Accuracy)** 하나만으로는 모델 성능을 평가하기 어렵고,  
     AUC·Brier Score·Expected Calibration Error(ECE)를 함께 고려하는 지표가 필요하다.
   - 이를 반영해 학습 코드에서 `combined_score()`를 정의하고,  
     \[
     \text{Score} = 0.5 \times (1 - \text{AUC}) + 0.25 \times \text{Brier} + 0.25 \times \text{ECE}
     \]
     형태의 내부 평가지표를 사용하여  
     **분류 성능과 확률 보정(calibration)을 동시에 최적화하는 방향**으로 분석·모델링을 진행하였다.

---

## 2. 상세 데이터 분석 방법론

### 1) 데이터 분석 방법론 상세

#### (1) 전체 분석 파이프라인 개요

데이터 분석 및 모델링 파이프라인은 다음과 같이 정리된다.

1. **원천 데이터 적재**
   - `train.csv`, `train/A.csv`, `train/B.csv` 로드
2. **기본 전처리**
   - `Age` → `Age_num`, `TestDate` → `Year`, `Month`, `YearMonthIndex`
3. **1차 도메인 피처 생성**
   - `preprocess_A()`, `preprocess_B()`  
   → 검사별 반응시간/정확도·정답률·설문 점수 등 요약 피처 생성
4. **2차 도메인 피처 생성**
   - `add_features_A()`, `add_features_B()`  
   → Speed–Accuracy, CV, log-ratio, YearMonthIndex 등 파생
5. **PK 히스토리 및 Delta(B-only) 생성**
   - 그룹 기준 정렬 후 `pk_hist_*`, `delta_B*_…` 생성
6. **정규화 통계 계산 및 저장**
   - `Age_num_z`, `YearMonthIndex_z` 및 통계량(`normalization_stats.pkl`)
7. **EDA 수행**
   - 기본 분포, 상관, Label 연관성, 시각화 등 통해  
     피처 선택·모델 구조(A/B 분리, PK Stats/Delta 활용 여부) 의사결정
8. **K-Fold 학습 및 평가**
   - `2_Train_Models_v18_delta_logratio.py`  
   - Fold별 PK Stats 생성, A/B 모델 학습, Isotonic Regression 보정,  
     AUC/Brier/ECE 및 Combined Score 기반 성능 비교
9. **최종 분석 결과 정리**
   - 버전(v0~v18+Delta+log_ratio)별 성능 비교 및  
     최종 버전 선정 근거·데이터 인사이트 문서화

#### (2) 핵심 모듈 역할 정리

- `convert_age`, `split_testdate`  
  → 연령·시점을 수치형으로 일관성 있게 변환
- `seq_mean`, `seq_std`, `masked_operation`, `seq_rate_*`  
  → 시퀀스(콤마 구분 문자열) 형태 로그를 **벡터형 요약값**으로 변환하는 유틸
- `preprocess_A`, `preprocess_B`  
  → A/B형 검사별 1차 도메인 피처 생성 (속도 예측, 정지 예측, Stroop, Flanker, 다중과제 등)
- `add_features_A`, `add_features_B`  
  → log-ratio, CV, Speed–Accuracy, YearMonthIndex 등 2차 피처 생성
- PK 히스토리 생성 블록  
  → `pk_hist_total_count`, `pk_hist_A_count`, `pk_hist_B_count`, `pk_hist_gap_from_prev`
- `add_delta_features_pk`  
  → B형 수치 피처에 대해 PK별 직전 검사와의 차이를 `delta_*`로 생성
- `expected_calibration_error`, `combined_score`  
  → ECE 및 AUC/Brier/ECE 기반 종합 지표 계산  
    (데이터 분석/모델 선택의 핵심 기준으로 활용)

---

### 2) 데이터 분석 상세

#### (1) 기본 분포 및 구조 분석

- **라벨/검사 유형**
  - A/B형별 Label 비율과 검사 횟수 분포를 비교해  
    어떤 유형·집단에서 상대적으로 사고 위험이 높은지 거시적으로 파악
- **연령·시점**
  - `Age_num`, `Age_num_z` 히스토그램과 `YearMonthIndex` 추이를 확인하여  
    특정 연령대/시기에 데이터가 편중되지 않는지, 계절성/트렌드가 있는지 점검
- **검사 횟수**
  - `pk_hist_total_count` 분포를 통해
    - 1~2회 검사 후 더 이상 기록이 없는 PK
    - 여러 해에 걸쳐 반복 검사된 PK  
    를 구분하고, 이후 분석에서 필요한 경우 그룹별 비교를 위한 기준으로 활용

#### (2) 인지검사별 피처 분석

- **반응시간/정확도 분포**
  - A1/A2(속도·정지 예측), A3(주의 전환), A4(Stroop), B3(신호등), B4(Flanker) 등  
    핵심 과제의 `*_rt_mean`, `*_rt_std`, `*_acc_*` 분포 확인
  - 이상치(outlier) 후보(극단적 반응시간, 지나치게 낮은 정확도)를 확인하여  
    전처리/모델링에서의 처리 방식을 검토

- **조건 간 차이 및 log-ratio**
  - Stroop/Flanker 계열
    - 조건별 평균/정확도 차이 및 log-ratio(`A4_stroop_*`, `B4_flanker_*`)를 통해  
      간섭 효과 크기가 어느 정도 범위에서 움직이는지 확인
  - 주의 전환/시야각 계열
    - `A3_valid_acc` vs `A3_invalid_acc`, `B1/B2_change_acc` vs `nonchange_acc` 등  
      조건별 난이도 차이가 일관되게 나타나는지 검토

- **Speed–Accuracy 및 CV**
  - `*_speed_acc_tradeoff`, `*_rt_cv` 분포를 통해
    - 빠른 대신 오류가 많은 유형
    - 느리지만 정확한 유형  
    등을 구분할 수 있는지, 값 범위가 안정적인지 확인

#### (3) 히스토리·Delta·상관 분석

- **PK 히스토리**
  - `pk_hist_A_count`, `pk_hist_B_count`, `pk_hist_gap_from_prev`를 이용해
    - 반복 검사 빈도가 높은 PK의 인지지표가 시간이 지날수록 안정화되는지
    - 일정 간격 이후 검사에서 급격한 성능 변화가 나타나는지  
    등을 탐색

- **Delta(B-only)**
  - `delta_B*_…` 피처의 분포를 확인하여
    - 평균적으로 변화가 0 근처에 몰려 있는지
    - 특정 과제에서만 변화폭이 큰지  
    등을 파악하고, 노이즈로 볼 것인지 의미 있는 신호로 볼 것인지 판단

- **상관 구조**
  - 반응시간·정확도·log-ratio·히스토리·Delta 피처 간 상관계수 행렬을 통해  
    피처 그룹 간 중복/보완 관계를 파악
  - 트리 기반 모델의 특성상 강한 상관이 존재해도 필수적으로 제거하지는 않되,  
    도메인 해석이 불명확한 피처는 중요도가 낮을 경우 정리 대상 후보로 고려

---

### 3) 결과 및 인사이트

데이터 분석 결과를 바탕으로 최종적으로 취한 전략과 인사이트는 다음과 같다.

1. **A/B 분리 모델 채택 근거**
   - EDA에서 확인한 바와 같이 A형과 B형은
     - 과제 구성, 난이도, 세부 측정 영역이 서로 다르고,
     - A형에는 Delta 피처의 의미가 상대적으로 약한 반면,
     - B형에는 반복 검사 간 변화(Delta)가 중요한 정보를 담고 있다.
   - 따라서
     - **모델 A**: A형 전용 – `Base + History + Normalization + log_ratio`
     - **모델 B**: B형 전용 – `Base + PK Stats + History + Normalization + Delta(B-only) + log_ratio`  
     구조를 채택하여, 각 유형에 맞는 정보를 최대한 활용하도록 설계하였다.

2. **핵심 인지 피처 선정 인사이트**
   - Stroop/Flanker, 주의 전환, 시야각 등  
     도메인상 인지 기능과 사고 위험의 연관성이 높은 과제들의 log-ratio·정확도 지표를  
     **핵심 인지 리스크 피처**로 두고,
   - Speed–Accuracy, CV, 히스토리/Delta는 이러한 인지 기능이  
     시간·개인 간 어떻게 달라지는지를 보완하는 피처로 활용하였다.

3. **평가 기준(Combined Score) 중심 모델 선택**
   - 데이터 분석 단계에서 AUC·Brier·ECE 각각의 의미를 검토하고,
     - AUC: 분리 성능
     - Brier: 확률 예측의 평균 제곱오차
     - ECE: 예측 확률과 실제 빈도의 일치도
   - 위 세 지표를 동시에 반영하는 Combined Score를 설계함으로써,  
     “잘 맞는 확률”을 제공하는 방향으로 피처·모델 구조를 조정하였다.
   - 이 과정에서
     - log-ratio 도입, Delta(B-only) 추가, PK Stats 활용 여부 등  
       데이터 관련 설계 변경이 실제 Combined Score 개선에 기여하는지 반복적으로 검증하였다.

---

## 3. 부록

본 보고서에서는 지면상 수치를 모두 싣지 않고, 주요 도표·시각화를 다음과 같이 정리할 수 있다.

- **[표 1] 메타 데이터 요약 통계**
  - `Label` 비율, A/B형 비율, `PrimaryKey`별 검사 횟수 요약 등

- **[그림 1] 연령 및 검사 시점 분포**
  - `Age_num`, `Age_num_z`, `YearMonthIndex` 히스토그램/시계열

- **[그림 2] 주요 과제별 반응시간/정확도 분포**
  - A1~A4, B1~B5의 `*_rt_mean`, `*_acc_*` 박스플롯·히스토그램

- **[표 2] 피처 그룹 간 상관계수 행렬**
  - 반응시간, 정확도, log-ratio, 히스토리, Delta 피처 간 상관 구조

- **[그림 3] Decile별 Label 비율 및 Calibration Plot**
  - 예측 확률 구간별 실제 Label 비율을 비교하여 보정 상태(ECE) 시각화

- **[표 3] 버전별(v0 ~ v18+Delta+log_ratio) 성능 비교**
  - AUC, Brier, ECE, Combined Score 요약
  - 최종 버전 선택 근거 제시용

- **[파일 목록]**
  - `data/all_train_data.feather` : 모든 전처리·피처가 반영된 학습/EDA 공용 데이터
  - `model/normalization_stats.pkl` : Age/YearMonthIndex 정규화 통계
  - `model/pk_stats_final.csv` : K-Fold 기반 PK 통계 피처
  - `notebooks/` 혹은 `eda/` : EDA용 시각화 코드 및 결과 그림 저장 위치

위와 같은 구조로 정리하면, 모델 개발 보고서와는 별도로  
**“데이터가 어떤 특성을 가지며, 그에 맞춰 어떤 분석·모델링 전략을 선택했는지”**를  
명확하게 전달할 수 있다.
